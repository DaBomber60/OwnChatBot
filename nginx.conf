events {
    worker_connections 1024;
}

http {
    upstream ownchatbot {
        server app:3000;
    }

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=general:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;

    server {
        listen 80;
        server_name _;

        # NOTE: This configuration is HTTP-only. In production with TLS termination
        # you would typically have a separate 443 server block (or an upstream load balancer)
        # providing certificates. The generic improvements below are still useful inside
        # a container behind a reverse proxy or terminating ingress.

        # Allow larger JSON payloads (character generation / imports)
        client_max_body_size 500M;
        client_body_timeout 300s;

        # Rate limiting
        limit_req zone=general burst=20 nodelay;

    # Security headers (adjust X-Frame-Options if you need embedding; DENY is strict)
    add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Referrer-Policy strict-origin-when-cross-origin;
    add_header Permissions-Policy "interest-cohort=()";
    # Example CSP (commented out until validated for your assets). Uncomment & tailor when ready.
    # add_header Content-Security-Policy "default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; connect-src 'self';";

        # Gzip compression
        gzip on;
        gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

        # Special rate limiting for auth endpoints
        location ~ ^/api/auth/ {
            limit_req zone=login burst=5 nodelay;
            proxy_pass http://ownchatbot;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # Chat API with streaming Server-Sent Events (SSE) support
        location /api/chat {
            proxy_pass http://ownchatbot;
            proxy_http_version 1.1;
            # Do NOT send WebSocket upgrade headers for SSE; keep the connection persistent
            proxy_set_header Upgrade '';
            proxy_set_header Connection 'keep-alive';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # Streaming optimizations
            proxy_buffering off;
            proxy_cache off;
            proxy_connect_timeout 60s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
            gzip off; # ensure no compression for SSE
            
            # SSE response headers (use add_header so client receives them)
            add_header Cache-Control "no-cache, no-transform" always;
            add_header X-Accel-Buffering "no" always;
        }

        # Long-running AI character generation endpoint (non-streaming but can be slow)
        # Learned need: larger timeouts + disable buffering to avoid premature upstream timeouts.
        location /api/characters/generate {
            proxy_pass http://ownchatbot;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Extended timeouts (tune if typical generation < 60s)
            proxy_connect_timeout 60s;
            proxy_send_timeout 600s;
            proxy_read_timeout 600s;

            # Disable buffering to start sending data ASAP if implementation later streams
            proxy_buffering off;
            proxy_request_buffering off;
            add_header X-Accel-Buffering "no" always;

            # Explicit no-store caching semantics
            add_header Cache-Control "no-store" always;
        }

        # Large database import endpoint (huge body uploads & long processing)
        location /api/database/import {
            proxy_pass http://ownchatbot;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Very long timeouts for large imports
            proxy_connect_timeout 300s;
            proxy_send_timeout 1800s;  # 30 minutes
            proxy_read_timeout 1800s;  # 30 minutes

            # Disable buffering
            proxy_buffering off;
            proxy_request_buffering off;

            # Specific body limits
            client_max_body_size 500M;
            client_body_timeout 1800s;

            add_header Cache-Control "no-store" always;
            add_header X-Accel-Buffering "no" always;
        }

        # Main application (generic); keep Upgrade only if you expect websocket usage (e.g. Next.js dev / future features)
        location / {
            proxy_pass http://ownchatbot;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # Timeout settings for streaming
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 300s;

            # Conservative buffering (leave on here); consider tuning if many long-running endpoints appear
        }

        # Health check endpoint
        location /api/health {
            access_log off;
            proxy_pass http://ownchatbot;
        }

        # Custom error pages for easier upstream diagnostics (optional)
        error_page 502 503 504 /custom_50x.html;
        location = /custom_50x.html {
            internal;
            add_header Cache-Control "no-store";
            return 200 'Upstream temporarily unavailable';
        }
    }
}
